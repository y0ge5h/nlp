{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation \n",
    "\n",
    "Keras provides the ImageDataGenerator class that defines the configuration for image data preparation and augmentation. This includes capabilities such as:\n",
    "\n",
    "Sample-wise standardization.\n",
    "Feature-wise standardization.\n",
    "ZCA whitening.\n",
    "Random rotation, shifts, shear and flips.\n",
    "Dimension reordering.\n",
    "Save augmented images to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "An augmented image generator can be created as follows:\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "Rather than performing the operations on your entire image dataset in memory, the API is designed to be iterated by the deep learning model fitting process, creating augmented image data for you just-in-time. This reduces your memory overhead, but adds some additional time cost during model training.\n",
    "\n",
    "After you have created and configured your ImageDataGenerator, you must fit it on your data. This will calculate any statistics required to actually perform the transforms to your image data. You can do this by calling the fit() function on the data generator and pass it your training dataset.\n",
    "\n",
    "\n",
    "datagen.fit(train)\n",
    "The data generator itself is in fact an iterator, returning batches of image samples when requested. We can configure the batch size and prepare the data generator and get batches of images by calling the flow() function.\n",
    "\n",
    "\n",
    "X_batch, y_batch = datagen.flow(train, train, batch_size=32)\n",
    "Finally we can make use of the data generator. Instead of calling the fit() function on our model, we must call the fit_generator() function and pass in the data generator and the desired length of an epoch as well as the total number of epochs on which to train.\n",
    "\n",
    "\n",
    "fit_generator(datagen, samples_per_epoch=len(train), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Standardization\n",
    "It is also possible to standardize pixel values across the entire dataset. \n",
    "This is called feature standardization and mirrors the type of standardization often performed for each column in a tabular dataset.\n",
    "\n",
    "You can perform feature standardization by setting the featurewise_center and featurewise_std_normalization arguments on the ImageDataGenerator class. \n",
    "These are in fact set to True by default and creating an instance of ImageDataGenerator with no arguments will have the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize images across the dataset, mean=0, stdev=1\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZCA Whitening\n",
    "A whitening transform of an image is a linear algebra operation that reduces the redundancy in the matrix of pixel images.\n",
    "\n",
    "Less redundancy in the image is intended to better highlight the structures and features in the image to the learning algorithm.\n",
    "\n",
    "Typically, image whitening is performed using the Principal Component Analysis (PCA) technique. More recently, an alternative called ZCA (learn more in Appendix A of this tech report) shows better results and results in transformed images that keeps all of the original dimensions and unlike PCA, resulting transformed images still look like their originals.\n",
    "\n",
    "You can perform a ZCA whitening transform by setting the zca_whitening argument to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZCA whitening\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Rotations\n",
    "Sometimes images in your sample data may have varying and different rotations in the scene.\n",
    "\n",
    "You can train your model to better handle rotations of images by artificially and randomly rotating images from your dataset during training.\n",
    "\n",
    "The example below creates random rotations of the MNIST digits up to 90 degrees by setting the rotation_range argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Rotations\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Shifts\n",
    "Objects in your images may not be centered in the frame. They may be off-center in a variety of different ways.\n",
    "\n",
    "You can train your deep learning network to expect and currently handle off-center objects by artificially creating shifted versions of your training data. Keras supports separate horizontal and vertical random shifting of training data by the width_shift_range and height_shift_range arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Shifts\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Flips\n",
    "Another augmentation to your image data that can improve performance on large and complex problems is to create random flips of images in your training data.\n",
    "\n",
    "Keras supports random flipping along both the vertical and horizontal axes using the vertical_flip and horizontal_flip arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Flips\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Augmented Images to File\n",
    "The data preparation and augmentation is performed just in time by Keras.\n",
    "\n",
    "This is efficient in terms of memory, but you may require the exact images used during training. For example, perhaps you would like to use them with a different software package later or only generate them once and use them on multiple different deep learning models or configurations.\n",
    "\n",
    "Keras allows you to save the images generated during training. The directory, filename prefix and image file type can be specified to the flow() function before training. Then, during training, the generated images will be written to file.\n",
    "\n",
    "The example below demonstrates this and writes 9 images to a “images” subdirectory with the prefix “aug” and the file type of PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save augmented images to file\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator()\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "os.makedirs('images')\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, save_to_dir='images', save_prefix='aug', save_format='png'):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips For Augmenting Image Data with Keras\n",
    "Image data is unique in that you can review the data and transformed copies of the data and quickly get an idea of how the model may be perceive it by your model.\n",
    "\n",
    "Below are some times for getting the most from image data preparation and augmentation for deep learning.\n",
    "\n",
    "Review Dataset. Take some time to review your dataset in great detail. Look at the images. Take note of image preparation and augmentations that might benefit the training process of your model, such as the need to handle different shifts, rotations or flips of objects in the scene.\n",
    "Review Augmentations. Review sample images after the augmentation has been performed. It is one thing to intellectually know what image transforms you are using, it is a very different thing to look at examples. Review images both with individual augmentations you are using as well as the full set of augmentations you plan to use. You may see ways to simplify or further enhance your model training process.\n",
    "Evaluate a Suite of Transforms. Try more than one image data preparation and augmentation scheme. Often you can be surprised by results of a data preparation scheme you did not think would be beneficial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
